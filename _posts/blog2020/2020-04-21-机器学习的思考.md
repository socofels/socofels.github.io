---
layout: article
title: 机器学习的一些思考与总结
tags: 机器学习
aside:
  toc: true
article_header:
  type: cover
  image:
    src: assets/images/background/pic/sky.jpg
---
# 关于机器学习的一点思考
机器学习看似算法千千万，但万变不离其宗，目前的机器学习其实就解决了两个基础问题。
1. 将问题描述为一个凸函数
2. 求凸函数的极值

同时呢，在解决这两个基础问题上，又提出了很多的优化方案。
- img
接下来我们讨论，机器学习到底是如何实现的，为什么机器学习可行？
## 将问题描述为一个凸函数
### 那么我们怎么样将问题描述为一个凸函数呢？
#### 什么是猜想函数
例如下图，为美国新冠病毒感染人数的数据，我们想要通过数据预测未来几天的感染人数，
那么怎么样将这个问题转为凸函数呢？

- ![](https://socofels.github.io/assets/images/generate_img/covid-19.jpg){:width="400px"}

**有人说可以使用一元函数拟合:**
- ![](https://socofels.github.io/assets/images/generate_img/covid-19-1.jpg){:width="400px"}

**也有人说可以使用二元函数拟合：**
- ![](https://socofels.github.io/assets/images/generate_img/covid-19-2.jpg){:width="400px"}

**还有人说用更高次函数，世界上没有他拟合不了的数据**
- ![](https://socofels.github.io/assets/images/generate_img/covid-19-3.jpg){:width="400px"}

以上这几个这里就是我们常所说的**猜想函数(hypothesis function)**

现在人云亦云，我们该相信谁的预测呢？有说一元函数好的，有说高阶函数好的，该信谁？

我们能否用一个式子表达所有的猜想呢？答案是**能！**
- $$y=w_1x_1^1+w_2x^2_2+w_3x_3^3+w_4x_4^4+W_5x_5^5+b$$

若是想要得到一元方程，让$w_2 w_3 w_4 w_5 =0$即可，这样以来我们可以用一个式子来表达1元到5元
的所有方程，只要修改$w_1 w_2 w_3 w_4 w_5$就可以得到不同的方程。

>题外话：这里你可能会问，为什么他们都用的幂函数函数来表示，而不采用sinx，或者其他函数呢？
>这里不得不提到一位非常牛掰的人物，泰勒。
>
>![](https://socofels.github.io/assets/images/blogimg/Taylor.jpeg){:width="100px"}
>泰勒曾经说过任意函数都能展开为幂函数。例如
>
>![](https://socofels.github.io/assets/images/blogimg/formula.png){:width="300px"}
>
>**所以理论上来说，我们可以使用幂函数表示任意形状的函数，这就是为什么用幂函数的原因。**


#### 有了猜想函数，参数$w_1 w_2 w_3 w_4 w_5$可以有无穷多重选择，如何选择最好的那个呢？
如果有办法在众多函数选择最好的一个就好了，于是就有了loss函数，就是我们前面所说的凸函数。
>**loss函数=凸函数**

- 我们使用一个凸函数来计算每个人预测误差，找到误差最小那个，我们就相信他。
- 比如我可以这样设置loss函数，求每天预测感染人数与实际感染人数的差值，总和起来。
    - 至于怎么求凸函数的最小值，那是下一节内容[求凸函数的极值](#求凸函数的极值)
- 结果万万没想到5次方的猜想获胜，对于之前的数据都是100%拟合，但是对于4月21日出的新数据，它的误差
却是最大的。这是为什么呢？
    - 因为这位同学为了追求极致100%拟合之前的数据，相当于钻牛角尖得到了一个猜想函数，
    它的确是会经过每一个点，但是对于未来数据，却给不出一个准确的预测，
    这个情况就叫过拟合(overfit)。说得了过去，预测不了未来。
    可以通过添加[正则项](#正则项)来解决这个问题。

#### 我应该如何设置loss函数
- loss函数应该根据实际问题，猜想函数具体分析，例如
    - 预测流感人数，loss函数可以设置为：计算预测感染人数与实际感染人数差值的平方
    - 又或者是逻辑问题，交叉熵损失函数
- 总的来说就两点要求
    - **这个loss函数得是一个凸函数，有最小值**
    - **loss函数与猜想函数的关系是，同一组w参数下，loss函数输出值越小，猜想函数的预测应该越准确。**



## <a id="求凸函数的极值">求凸函数的极值<a>
### 求极值
如何求一个凸函数的极值点？我们可以使用导数。
例如：假设y是预测值，g是实际值,n是样本数量
- hypothesis：$$y=wx+b$$
- loss：$$cost =\sum_{0}^{n}(y-g)^2$$
- 将猜想带入可得：
- $$cost =\sum_{1}^{n}(wx+b-g)^2$$
通过求导可以得到它的极值点为导数=0时有极值且等于最值。这是猜想函数为一元函数的情形。若是更高幂次函数，
那么就不一定能求到最值，因为通过求导求得的导数幂次大于1，那么loss函数会有多个极值点，此时得到极值也
不一定是最值。
<!--more-->

---
